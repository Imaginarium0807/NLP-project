{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "hygiene_text_path= \"./Hygiene/hygiene.dat\"\n",
    "hygiene_labels_path= \"./Hygiene/hygiene.dat.labels\"\n",
    "hygiene_additional_path= \"./Hygiene/hygiene.dat.additional\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import gensim\n",
    "import nltk\n",
    "import spacy\n",
    "\n",
    "from UtilWordEmbedding import MeanEmbeddingVectorizer\n",
    "\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "from gensim.parsing.preprocessing import strip_tags, strip_punctuation, strip_numeric, strip_short\n",
    "from gensim.parsing.preprocessing import strip_multiple_whitespaces, strip_non_alphanum, remove_stopwords, stem_text\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "STOP_WORDS = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "SEED=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and preprocess\n",
    "# https://radimrehurek.com/gensim/parsing/preprocessing.html\n",
    "FILTERS_LIST = [lambda x: x.lower(), # lowercase  \n",
    "                strip_tags, # remove tags\n",
    "                strip_punctuation, # replace punctuation characters with spaces\n",
    "                strip_multiple_whitespaces, # remove repeating whitespaces\n",
    "                # strip_numeric, # remove numbers\n",
    "                gensim.parsing.preprocessing.remove_stopwords, # remove stopwords\n",
    "                strip_short, # remove words less than minsize=3 characters long]\n",
    "                stem_text]\n",
    "def preprocess(text):\n",
    "    \"\"\"\n",
    "    strip_tags, strip_punctuation, strip_multiple_whitespaces, strip_numeric, \n",
    "    \"\"\"\n",
    "    result_stemmed = []\n",
    "    for token in gensim.parsing.preprocessing.preprocess_string(text, FILTERS_LIST):\n",
    "        result_stemmed.append(WordNetLemmatizer().lemmatize(token))\n",
    "    return result_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 13299/13299 [01:37<00:00, 136.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "texts = []\n",
    "preprocessed_texts = []\n",
    "\n",
    "with open(hygiene_text_path) as f:\n",
    "    texts = f.readlines()\n",
    "    \n",
    "for _text in tqdm(texts):\n",
    "    result_stemmed = preprocess(_text)\n",
    "    preprocessed_texts.append(result_stemmed)\n",
    "    \n",
    "all_preprocessed_texts = [\" \".join(_text) for _text in preprocessed_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13299 entries, 0 to 13298\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   label               13299 non-null  object\n",
      " 1   text                13299 non-null  object\n",
      " 2   preprocessed_texts  13299 non-null  object\n",
      " 3   tokenized_texts     13299 non-null  object\n",
      " 4   cuisines_offered    13299 non-null  object\n",
      " 5   zipcode             13299 non-null  object\n",
      " 6   num_reviews         13299 non-null  object\n",
      " 7   avg_rating          13299 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 831.3+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>preprocessed_texts</th>\n",
       "      <th>tokenized_texts</th>\n",
       "      <th>cuisines_offered</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>avg_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The baguettes and rolls are excellent, and alt...</td>\n",
       "      <td>baguett roll excel haven tri excit dozen plu t...</td>\n",
       "      <td>[baguett, roll, excel, haven, tri, excit, doze...</td>\n",
       "      <td>['Vietnamese', 'Sandwiches', 'Restaurants']</td>\n",
       "      <td>98118</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I live up the street from Betty. &amp;#160;When my...</td>\n",
       "      <td>live street betti 160 sister town spring break...</td>\n",
       "      <td>[live, street, betti, 160, sister, town, sprin...</td>\n",
       "      <td>['American (New)', 'Restaurants']</td>\n",
       "      <td>98109</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm worried about how I will review this place...</td>\n",
       "      <td>worri review place strongli think bad night pl...</td>\n",
       "      <td>[worri, review, place, strongli, think, bad, n...</td>\n",
       "      <td>['Mexican', 'Restaurants']</td>\n",
       "      <td>98103</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Why can't you access them on Google street vie...</td>\n",
       "      <td>access googl street view like medina yarrow po...</td>\n",
       "      <td>[access, googl, street, view, like, medina, ya...</td>\n",
       "      <td>['Mexican', 'Tex-Mex', 'Restaurants']</td>\n",
       "      <td>98112</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Things to like about this place: homemade guac...</td>\n",
       "      <td>thing like place homemad guacamol varieti tast...</td>\n",
       "      <td>[thing, like, place, homemad, guacamol, variet...</td>\n",
       "      <td>['Mexican', 'Restaurants']</td>\n",
       "      <td>98102</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text                                 preprocessed_texts                                    tokenized_texts                             cuisines_offered zipcode num_reviews avg_rating\n",
       "0     1  The baguettes and rolls are excellent, and alt...  baguett roll excel haven tri excit dozen plu t...  [baguett, roll, excel, haven, tri, excit, doze...  ['Vietnamese', 'Sandwiches', 'Restaurants']   98118           4          4\n",
       "1     1  I live up the street from Betty. &#160;When my...  live street betti 160 sister town spring break...  [live, street, betti, 160, sister, town, sprin...            ['American (New)', 'Restaurants']   98109          21          4\n",
       "2     1  I'm worried about how I will review this place...  worri review place strongli think bad night pl...  [worri, review, place, strongli, think, bad, n...                   ['Mexican', 'Restaurants']   98103          14          3\n",
       "3     0  Why can't you access them on Google street vie...  access googl street view like medina yarrow po...  [access, googl, street, view, like, medina, ya...        ['Mexican', 'Tex-Mex', 'Restaurants']   98112          42          4\n",
       "4     0  Things to like about this place: homemade guac...  thing like place homemad guacamol varieti tast...  [thing, like, place, homemad, guacamol, variet...                   ['Mexican', 'Restaurants']   98102          12          3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 546\n",
    "\n",
    "# labels \n",
    "with open(hygiene_labels_path, 'r') as f:\n",
    "    labels = [l.rstrip() for l in f]\n",
    "\n",
    "# texts = []\n",
    "# with open(hygiene_text_path, 'r') as f:\n",
    "#     texts = f.read().splitlines(True)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\"label\":labels, \"text\": texts, \n",
    "                   \"preprocessed_texts\": all_preprocessed_texts,\n",
    "                   \"tokenized_texts\": preprocessed_texts})\n",
    "hygiene_additional = pd.read_csv(hygiene_additional_path,  \n",
    "                                 names=[\"cuisines_offered\", \"zipcode\", \"num_reviews\", \"avg_rating\"],\n",
    "                                 dtype={\"cuisines_offered\": str, \n",
    "                                        \"zipcode\": str,\n",
    "                                        \"num_reviews\": str})\n",
    "df = df.join(hygiene_additional)\n",
    "df['avg_rating'] = df['avg_rating'].apply(lambda x: str(int(round(x, 0))))\n",
    "\n",
    "print(df.info())\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(546, 5) (546, 5) (546, 5) (546,)\n",
      "(12753, 5) (12753, 5) (12753, 5) (12753,)\n",
      "text                object\n",
      "cuisines_offered    object\n",
      "zipcode             object\n",
      "num_reviews         object\n",
      "avg_rating          object\n",
      "dtype: object preprocessed_texts    object\n",
      "cuisines_offered      object\n",
      "zipcode               object\n",
      "num_reviews           object\n",
      "avg_rating            object\n",
      "dtype: object tokenized_texts     object\n",
      "cuisines_offered    object\n",
      "zipcode             object\n",
      "num_reviews         object\n",
      "avg_rating          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "train_df = df[df[\"label\"] != \"[None]\"]\n",
    "test_df = df[df[\"label\"] == \"[None]\"]\n",
    "\n",
    "additional_feats = [\"cuisines_offered\", \"zipcode\", \"num_reviews\", \"avg_rating\"]\n",
    "\n",
    "train = train_df[[\"text\"] + additional_feats]\n",
    "train_preprocessed = train_df[[\"preprocessed_texts\"] + additional_feats]\n",
    "train_tokenized = train_df[[\"tokenized_texts\"] + additional_feats]\n",
    "train_labels = train_df[\"label\"].astype(int) # needed by sklearn\n",
    "\n",
    "test = test_df[[\"text\"] + additional_feats]\n",
    "test_preprocessed = test_df[[\"preprocessed_texts\"] + additional_feats]\n",
    "test_tokenized = test_df[[\"tokenized_texts\"] + additional_feats]\n",
    "test_labels = test_df[\"label\"]\n",
    "\n",
    "print(train.shape, train_preprocessed.shape, train_tokenized.shape, train_labels.shape)\n",
    "print(test.shape, test_preprocessed.shape, test_tokenized.shape, test_labels.shape)\n",
    "print(train.dtypes, train_preprocessed.dtypes, train_tokenized.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cuisines_offered</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>avg_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The baguettes and rolls are excellent, and alt...</td>\n",
       "      <td>['Vietnamese', 'Sandwiches', 'Restaurants']</td>\n",
       "      <td>98118</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I live up the street from Betty. &amp;#160;When my...</td>\n",
       "      <td>['American (New)', 'Restaurants']</td>\n",
       "      <td>98109</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm worried about how I will review this place...</td>\n",
       "      <td>['Mexican', 'Restaurants']</td>\n",
       "      <td>98103</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why can't you access them on Google street vie...</td>\n",
       "      <td>['Mexican', 'Tex-Mex', 'Restaurants']</td>\n",
       "      <td>98112</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Things to like about this place: homemade guac...</td>\n",
       "      <td>['Mexican', 'Restaurants']</td>\n",
       "      <td>98102</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                             cuisines_offered zipcode num_reviews avg_rating\n",
       "0  The baguettes and rolls are excellent, and alt...  ['Vietnamese', 'Sandwiches', 'Restaurants']   98118           4          4\n",
       "1  I live up the street from Betty. &#160;When my...            ['American (New)', 'Restaurants']   98109          21          4\n",
       "2  I'm worried about how I will review this place...                   ['Mexican', 'Restaurants']   98103          14          3\n",
       "3  Why can't you access them on Google street vie...        ['Mexican', 'Tex-Mex', 'Restaurants']   98112          42          4\n",
       "4  Things to like about this place: homemade guac...                   ['Mexican', 'Restaurants']   98102          12          3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessed_texts</th>\n",
       "      <th>cuisines_offered</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>avg_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baguett roll excel haven tri excit dozen plu t...</td>\n",
       "      <td>['Vietnamese', 'Sandwiches', 'Restaurants']</td>\n",
       "      <td>98118</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>live street betti 160 sister town spring break...</td>\n",
       "      <td>['American (New)', 'Restaurants']</td>\n",
       "      <td>98109</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>worri review place strongli think bad night pl...</td>\n",
       "      <td>['Mexican', 'Restaurants']</td>\n",
       "      <td>98103</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>access googl street view like medina yarrow po...</td>\n",
       "      <td>['Mexican', 'Tex-Mex', 'Restaurants']</td>\n",
       "      <td>98112</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thing like place homemad guacamol varieti tast...</td>\n",
       "      <td>['Mexican', 'Restaurants']</td>\n",
       "      <td>98102</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  preprocessed_texts                             cuisines_offered zipcode num_reviews avg_rating\n",
       "0  baguett roll excel haven tri excit dozen plu t...  ['Vietnamese', 'Sandwiches', 'Restaurants']   98118           4          4\n",
       "1  live street betti 160 sister town spring break...            ['American (New)', 'Restaurants']   98109          21          4\n",
       "2  worri review place strongli think bad night pl...                   ['Mexican', 'Restaurants']   98103          14          3\n",
       "3  access googl street view like medina yarrow po...        ['Mexican', 'Tex-Mex', 'Restaurants']   98112          42          4\n",
       "4  thing like place homemad guacamol varieti tast...                   ['Mexican', 'Restaurants']   98102          12          3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenized_texts</th>\n",
       "      <th>cuisines_offered</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>avg_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[baguett, roll, excel, haven, tri, excit, doze...</td>\n",
       "      <td>['Vietnamese', 'Sandwiches', 'Restaurants']</td>\n",
       "      <td>98118</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[live, street, betti, 160, sister, town, sprin...</td>\n",
       "      <td>['American (New)', 'Restaurants']</td>\n",
       "      <td>98109</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[worri, review, place, strongli, think, bad, n...</td>\n",
       "      <td>['Mexican', 'Restaurants']</td>\n",
       "      <td>98103</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[access, googl, street, view, like, medina, ya...</td>\n",
       "      <td>['Mexican', 'Tex-Mex', 'Restaurants']</td>\n",
       "      <td>98112</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[thing, like, place, homemad, guacamol, variet...</td>\n",
       "      <td>['Mexican', 'Restaurants']</td>\n",
       "      <td>98102</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     tokenized_texts                             cuisines_offered zipcode num_reviews avg_rating\n",
       "0  [baguett, roll, excel, haven, tri, excit, doze...  ['Vietnamese', 'Sandwiches', 'Restaurants']   98118           4          4\n",
       "1  [live, street, betti, 160, sister, town, sprin...            ['American (New)', 'Restaurants']   98109          21          4\n",
       "2  [worri, review, place, strongli, think, bad, n...                   ['Mexican', 'Restaurants']   98103          14          3\n",
       "3  [access, googl, street, view, like, medina, ya...        ['Mexican', 'Tex-Mex', 'Restaurants']   98112          42          4\n",
       "4  [thing, like, place, homemad, guacamol, variet...                   ['Mexican', 'Restaurants']   98102          12          3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.head())\n",
    "display(train_preprocessed.head())\n",
    "display(train_tokenized.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62650104 0.72474747 0.668357   0.68783693 0.60507246]\n",
      "Average F1-Score: 0.66250\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', ColumnTransformer(\n",
    "        [('cuisines_offered', CountVectorizer(min_df=10), 'cuisines_offered'),\n",
    "         ('zipcode', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['zipcode']),\n",
    "         ('num_reviews', CountVectorizer(max_df=7, token_pattern='\\d+'), 'num_reviews'),\n",
    "         ('avg_rating', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['avg_rating']),\n",
    "         ('text', TfidfVectorizer(\n",
    "                    stop_words='english',\n",
    "                    strip_accents='unicode',\n",
    "                    min_df=3,\n",
    "                    max_df=0.5,\n",
    "                    ngram_range=(1, 3),\n",
    "                    max_features=500), 'preprocessed_texts')],\n",
    "        remainder='passthrough',\n",
    "    )),\n",
    "    ('clf', MultinomialNB())\n",
    "], verbose=False)\n",
    "\n",
    "# pipeline.fit(X_train, y_train)\n",
    "# y_pred = pipeline.predict(X_test)\n",
    "# scores = metrics.f1_score(y_test, y_pred)\n",
    "scores = cross_val_score(pipeline, train_preprocessed, train_labels, cv=5, scoring= 'f1_macro')\n",
    "print(scores)\n",
    "print(\"Average F1-Score: %0.5f\" % np.average(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63461538 0.72222222 0.68965517 0.66037736 0.54347826]\n",
      "Average F1-Score: 0.65007\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', ColumnTransformer(\n",
    "        [('cuisines_offered', CountVectorizer(min_df=10), 'cuisines_offered'),\n",
    "         ('zipcode', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['zipcode']),\n",
    "         ('num_reviews', CountVectorizer(max_df=7, token_pattern='\\d+'), 'num_reviews'),\n",
    "         ('avg_rating', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['avg_rating']),\n",
    "         ('text', TfidfVectorizer(\n",
    "                    stop_words='english',\n",
    "                    strip_accents='unicode',\n",
    "                    min_df=3,\n",
    "                    max_df=0.5,\n",
    "                    ngram_range=(1, 3),\n",
    "                    max_features=500), 'text')],\n",
    "        remainder='passthrough',\n",
    "    )),\n",
    "    ('clf', MultinomialNB())\n",
    "], verbose=False)\n",
    "\n",
    "# pipeline.fit(X_train, y_train)\n",
    "# y_pred = pipeline.predict(X_test)\n",
    "# scores = metrics.f1_score(y_test, y_pred)\n",
    "scores = cross_val_score(pipeline, train, train_labels, cv=5, scoring= 'f1')\n",
    "print(scores)\n",
    "print(\"Average F1-Score: %0.5f\" % np.average(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1      2193\n",
       "2      1480\n",
       "3      1126\n",
       "4       934\n",
       "5       767\n",
       "6       675\n",
       "7       600\n",
       "8       484\n",
       "9       458\n",
       "10      403\n",
       "11      352\n",
       "12      315\n",
       "13      268\n",
       "14      246\n",
       "16      200\n",
       "15      199\n",
       "17      185\n",
       "18      160\n",
       "19      131\n",
       "20      125\n",
       "22      124\n",
       "21      124\n",
       "23      107\n",
       "24      101\n",
       "25       97\n",
       "28       86\n",
       "26       81\n",
       "27       77\n",
       "29       68\n",
       "30       60\n",
       "32       52\n",
       "33       51\n",
       "36       44\n",
       "37       44\n",
       "34       43\n",
       "31       43\n",
       "35       42\n",
       "39       39\n",
       "44       37\n",
       "38       33\n",
       "43       30\n",
       "47       28\n",
       "42       27\n",
       "40       26\n",
       "45       25\n",
       "46       25\n",
       "41       23\n",
       "54       22\n",
       "59       20\n",
       "55       15\n",
       "49       15\n",
       "52       15\n",
       "63       15\n",
       "51       14\n",
       "48       14\n",
       "62       14\n",
       "73       13\n",
       "57       12\n",
       "56       11\n",
       "50       11\n",
       "61       11\n",
       "53       10\n",
       "58       10\n",
       "66        9\n",
       "78        9\n",
       "83        8\n",
       "67        8\n",
       "89        8\n",
       "60        8\n",
       "65        7\n",
       "77        6\n",
       "93        6\n",
       "70        6\n",
       "64        6\n",
       "69        6\n",
       "84        5\n",
       "76        5\n",
       "112       5\n",
       "85        5\n",
       "100       4\n",
       "68        4\n",
       "74        4\n",
       "80        4\n",
       "91        4\n",
       "75        3\n",
       "72        3\n",
       "105       3\n",
       "107       3\n",
       "86        3\n",
       "122       3\n",
       "88        3\n",
       "101       3\n",
       "136       3\n",
       "142       3\n",
       "144       2\n",
       "130       2\n",
       "161       2\n",
       "123       2\n",
       "197       2\n",
       "110       2\n",
       "92        2\n",
       "177       2\n",
       "90        2\n",
       "71        2\n",
       "95        2\n",
       "148       2\n",
       "102       2\n",
       "125       2\n",
       "81        2\n",
       "132       2\n",
       "94        2\n",
       "116       2\n",
       "108       1\n",
       "118       1\n",
       "145       1\n",
       "266       1\n",
       "134       1\n",
       "121       1\n",
       "98        1\n",
       "243       1\n",
       "97        1\n",
       "568       1\n",
       "147       1\n",
       "260       1\n",
       "176       1\n",
       "233       1\n",
       "167       1\n",
       "109       1\n",
       "214       1\n",
       "193       1\n",
       "259       1\n",
       "162       1\n",
       "141       1\n",
       "139       1\n",
       "103       1\n",
       "106       1\n",
       "251       1\n",
       "232       1\n",
       "169       1\n",
       "253       1\n",
       "104       1\n",
       "181       1\n",
       "99        1\n",
       "189       1\n",
       "188       1\n",
       "203       1\n",
       "111       1\n",
       "79        1\n",
       "234       1\n",
       "129       1\n",
       "135       1\n",
       "127       1\n",
       "119       1\n",
       "210       1\n",
       "96        1\n",
       "268       1\n",
       "128       1\n",
       "171       1\n",
       "Name: num_reviews, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df['num_reviews'].value_counts()))\n",
    "df['num_reviews'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Thai', 'Restaurants']                                                          640\n",
       "['American (New)', 'Restaurants']                                                596\n",
       "['American (Traditional)', 'Restaurants']                                        589\n",
       "['Mexican', 'Restaurants']                                                       572\n",
       "['Pizza', 'Restaurants']                                                         524\n",
       "['Vietnamese', 'Restaurants']                                                    465\n",
       "['Japanese', 'Sushi Bars', 'Restaurants']                                        459\n",
       "['Sandwiches', 'Restaurants']                                                    430\n",
       "['Chinese', 'Restaurants']                                                       394\n",
       "['Italian', 'Pizza', 'Restaurants']                                              327\n",
       "['Japanese', 'Restaurants']                                                      282\n",
       "['Italian', 'Restaurants']                                                       274\n",
       "['Restaurants']                                                                  237\n",
       "['Fast Food', 'Mexican', 'Restaurants']                                          232\n",
       "['Delis', 'Restaurants']                                                         204\n",
       "['Cafes', 'Sandwiches', 'Restaurants']                                           195\n",
       "['Burgers', 'Fast Food', 'Restaurants']                                          180\n",
       "['Greek', 'Mediterranean', 'Restaurants']                                        177\n",
       "['American (Traditional)', 'Breakfast & Brunch', 'Restaurants']                  168\n",
       "['Fast Food', 'Sandwiches', 'Restaurants']                                       159\n",
       "['Burgers', 'Restaurants']                                                       136\n",
       "['Ethiopian', 'Restaurants']                                                     136\n",
       "['Irish', 'Restaurants']                                                         135\n",
       "['Delis', 'Sandwiches', 'Restaurants']                                           121\n",
       "['Dim Sum', 'Seafood', 'Cantonese', 'Chinese', 'Restaurants']                    118\n",
       "['Seafood', 'Restaurants']                                                        97\n",
       "['Barbeque', 'Restaurants']                                                       91\n",
       "['Italian', 'Pizza', 'Sandwiches', 'Restaurants']                                 86\n",
       "['French', 'Restaurants']                                                         85\n",
       "['Breakfast & Brunch', 'Restaurants']                                             84\n",
       "['Cafes', 'Restaurants']                                                          84\n",
       "['Creperies', 'Restaurants']                                                      84\n",
       "['Indian', 'Restaurants']                                                         80\n",
       "['Breakfast & Brunch', 'Cafes', 'Restaurants']                                    79\n",
       "['Vietnamese', 'Sandwiches', 'Restaurants']                                       77\n",
       "['Delis', 'Vietnamese', 'Sandwiches', 'Restaurants']                              76\n",
       "['Seafood', 'Fast Food', 'Fish & Chips', 'Restaurants']                           69\n",
       "['Breakfast & Brunch', 'American (New)', 'Restaurants']                           68\n",
       "['Indian', 'Buffets', 'Restaurants']                                              67\n",
       "['Japanese', 'Chinese', 'Restaurants']                                            64\n",
       "['German', 'Restaurants']                                                         64\n",
       "['Asian Fusion', 'Chinese', 'Restaurants']                                        63\n",
       "['Barbeque', 'Chinese', 'Restaurants']                                            59\n",
       "['Asian Fusion', 'Restaurants']                                                   53\n",
       "['Breakfast & Brunch', 'Sandwiches', 'Restaurants']                               51\n",
       "['Breakfast & Brunch', 'Seafood', 'Buffets', 'Restaurants']                       51\n",
       "['Mediterranean', 'Restaurants']                                                  49\n",
       "['American (New)', 'French', 'Restaurants']                                       47\n",
       "['Restaurants', 'Pizza']                                                          45\n",
       "['Delis', 'Italian', 'Restaurants']                                               44\n",
       "['American (Traditional)', 'Seafood', 'Restaurants']                              41\n",
       "['Mexican', 'Sandwiches', 'Restaurants']                                          41\n",
       "['British', 'Restaurants']                                                        41\n",
       "['American (Traditional)', 'Steakhouses', 'Restaurants']                          40\n",
       "['Steakhouses', 'Restaurants']                                                    40\n",
       "['American (Traditional)', 'Soup', 'Seafood', 'Restaurants']                      40\n",
       "['Pakistani', 'Indian', 'Restaurants']                                            38\n",
       "['Mexican', 'Tex-Mex', 'Restaurants']                                             38\n",
       "['Vegetarian', 'Vegan', 'Restaurants']                                            37\n",
       "['Filipino', 'Restaurants']                                                       37\n",
       "['Cantonese', 'Chinese', 'Restaurants']                                           37\n",
       "['Tapas Bars', 'Spanish', 'Basque', 'Restaurants']                                36\n",
       "['Tex-Mex', 'Restaurants']                                                        35\n",
       "['American (Traditional)', 'Burgers', 'Restaurants']                              34\n",
       "['Cheesesteaks', 'Sandwiches', 'Restaurants']                                     34\n",
       "['Seafood', 'Steakhouses', 'Restaurants']                                         34\n",
       "['Vietnamese', 'Chinese', 'Restaurants']                                          33\n",
       "['Dim Sum', 'Cantonese', 'Chinese', 'Restaurants']                                31\n",
       "['Breakfast & Brunch', 'Diners', 'Restaurants']                                   31\n",
       "['Mediterranean', 'Middle Eastern', 'Restaurants']                                31\n",
       "['Sushi Bars', 'Restaurants']                                                     29\n",
       "['Fast Food', 'Southern', 'Soul Food', 'Restaurants']                             29\n",
       "['American (Traditional)', 'Diners', 'Restaurants']                               28\n",
       "['Breakfast & Brunch', 'Vegetarian', 'Restaurants']                               28\n",
       "['American (Traditional)', 'Breakfast & Brunch', 'Diners', 'Restaurants']         27\n",
       "['Greek', 'Mediterranean', 'Middle Eastern', 'Restaurants']                       27\n",
       "['Seafood', 'Cantonese', 'Chinese', 'Restaurants']                                27\n",
       "['Burgers', 'American (New)', 'Restaurants']                                      26\n",
       "['Turkish', 'Mediterranean', 'Restaurants']                                       26\n",
       "['Barbeque', 'Chicken Wings', 'Restaurants']                                      26\n",
       "['Hawaiian', 'Restaurants']                                                       26\n",
       "['American (Traditional)', 'American (New)', 'Restaurants']                       25\n",
       "['Burgers', 'Gluten-Free', 'Restaurants']                                         23\n",
       "['Seafood', 'American (New)', 'Restaurants']                                      23\n",
       "['Hot Pot', 'Szechuan', 'Chinese', 'Restaurants']                                 23\n",
       "['Middle Eastern', 'Restaurants']                                                 23\n",
       "['Cuban', 'Caribbean', 'Sandwiches', 'Restaurants']                               23\n",
       "['Sushi Bars', 'Japanese', 'Hawaiian', 'Restaurants']                             23\n",
       "['Gluten-Free', 'Restaurants']                                                    22\n",
       "['Seafood', 'Chinese', 'Restaurants']                                             21\n",
       "['Cafes', 'French', 'Restaurants']                                                21\n",
       "['Cajun/Creole', 'Restaurants']                                                   21\n",
       "['Korean', 'Japanese', 'Chinese', 'Restaurants']                                  21\n",
       "['Dim Sum', 'Chinese', 'Restaurants']                                             21\n",
       "['Restaurants', 'Cafes']                                                          21\n",
       "['Breakfast & Brunch', 'Burgers', 'Restaurants']                                  21\n",
       "['Korean', 'Japanese', 'Restaurants']                                             20\n",
       "['Asian Fusion', 'Sushi Bars', 'Restaurants']                                     20\n",
       "['Indian', 'Himalayan/Nepalese', 'Restaurants']                                   20\n",
       "['Diners', 'Restaurants']                                                         20\n",
       "['Seafood', 'Breakfast & Brunch', 'Restaurants']                                  20\n",
       "['Dim Sum', 'Cantonese', 'Barbeque', 'Chinese', 'Restaurants']                    20\n",
       "['Breakfast & Brunch', 'American (New)', 'Cafes', 'Restaurants']                  19\n",
       "['Breakfast & Brunch', 'French', 'Restaurants']                                   19\n",
       "['Cambodian', 'Restaurants']                                                      19\n",
       "['Pizza', 'Sandwiches', 'Restaurants']                                            18\n",
       "['Chinese', 'Dim Sum', 'Seafood', 'Restaurants']                                  18\n",
       "['Greek', 'Restaurants']                                                          18\n",
       "['Fast Food', 'Chinese', 'Restaurants']                                           18\n",
       "['Pakistani', 'Indian', 'Buffets', 'Restaurants']                                 18\n",
       "['Russian', 'Restaurants']                                                        18\n",
       "['Modern European', 'American (New)', 'Restaurants']                              18\n",
       "['Brazilian', 'Restaurants']                                                      18\n",
       "['Fast Food', 'Japanese', 'Restaurants']                                          18\n",
       "['Tapas Bars', 'American (New)', 'Restaurants']                                   18\n",
       "['Tapas Bars', 'Restaurants']                                                     17\n",
       "['Breakfast & Brunch', 'Creperies', 'Restaurants']                                17\n",
       "['American (New)', 'Sandwiches', 'Restaurants']                                   17\n",
       "['Vegetarian', 'Restaurants']                                                     17\n",
       "['Seafood', 'Italian', 'Restaurants']                                             17\n",
       "['Korean', 'Restaurants']                                                         16\n",
       "['Burgers', 'Hot Dogs', 'Restaurants']                                            16\n",
       "['Vietnamese', 'Sandwiches', 'Japanese', 'Restaurants']                           16\n",
       "['Asian Fusion', 'Japanese', 'Restaurants']                                       16\n",
       "['American (Traditional)', 'Breakfast & Brunch', 'Burgers', 'Restaurants']        16\n",
       "['Barbeque', 'Soul Food', 'Restaurants']                                          16\n",
       "['Pizza', 'Gluten-Free', 'Restaurants']                                           16\n",
       "['American (Traditional)', 'Cafes', 'Restaurants']                                16\n",
       "['Mexican', 'Salvadoran', 'Latin American', 'Restaurants']                        16\n",
       "['Restaurants', 'Mexican']                                                        16\n",
       "['Breakfast & Brunch', 'Mexican', 'Restaurants']                                  15\n",
       "['Breakfast & Brunch', 'Vietnamese', 'Restaurants']                               15\n",
       "['Asian Fusion', 'Dim Sum', 'Vietnamese', 'Chinese', 'Restaurants']               15\n",
       "['Pakistani', 'Indian', 'Halal', 'Restaurants']                                   15\n",
       "['Asian Fusion', 'Japanese', 'Sushi Bars', 'Restaurants']                         15\n",
       "['Restaurants', 'Italian']                                                        15\n",
       "['African', 'Restaurants']                                                        14\n",
       "['Asian Fusion', 'Thai', 'Chinese', 'Restaurants']                                14\n",
       "['Moroccan', 'Restaurants']                                                       14\n",
       "['Delis', 'Vietnamese', 'Restaurants']                                            14\n",
       "['Mediterranean', 'Gastropubs', 'Restaurants']                                    14\n",
       "['Asian Fusion', 'Gluten-Free', 'Chinese', 'Restaurants']                         14\n",
       "['Thai', 'Chinese', 'Restaurants']                                                14\n",
       "['American (Traditional)', 'Breakfast & Brunch', 'Vegetarian', 'Restaurants']     14\n",
       "['Thai', 'Vietnamese', 'Restaurants']                                             14\n",
       "['Vegetarian', 'Vegan', 'Hot Dogs', 'Restaurants']                                14\n",
       "['Breakfast & Brunch', 'Delis', 'Burgers', 'Restaurants']                         14\n",
       "['Taiwanese', 'Chinese', 'Restaurants']                                           14\n",
       "['Vegetarian', 'Vietnamese', 'Restaurants']                                       14\n",
       "['Pizza', 'Gluten-Free', 'Vegan', 'Restaurants']                                  13\n",
       "['German', 'Sandwiches', 'Restaurants']                                           13\n",
       "['Tapas/Small Plates', 'Mediterranean', 'Restaurants']                            13\n",
       "['Creperies', 'Sandwiches', 'Restaurants']                                        13\n",
       "['Pizza', 'Fast Food', 'Restaurants']                                             13\n",
       "['Barbeque', 'Hawaiian', 'Restaurants']                                           13\n",
       "['Mexican', 'Latin American', 'Restaurants']                                      13\n",
       "['Breakfast & Brunch', 'Seafood', 'American (New)', 'Restaurants']                13\n",
       "['Pizza', 'American (New)', 'Restaurants']                                        13\n",
       "['Sandwiches', 'French', 'Restaurants']                                           13\n",
       "['Gastropubs', 'Restaurants']                                                     13\n",
       "['Shanghainese', 'Chinese', 'Restaurants']                                        13\n",
       "['Italian', 'Pizza', 'Cafes', 'Restaurants']                                      13\n",
       "['Vegetarian', 'Modern European', 'Mediterranean', 'Restaurants']                 13\n",
       "['Fondue', 'Gluten-Free', 'Restaurants']                                          13\n",
       "['Soup', 'Restaurants']                                                           13\n",
       "['German', 'Steakhouses', 'Restaurants']                                          13\n",
       "['American (Traditional)', 'Breakfast & Brunch', 'Seafood', 'Restaurants']        13\n",
       "['American (Traditional)', 'Sandwiches', 'Restaurants']                           13\n",
       "['Burgers', 'Sandwiches', 'Restaurants']                                          12\n",
       "['Modern European', 'Sandwiches', 'Restaurants']                                  12\n",
       "['Barbeque', 'Southern', 'Restaurants']                                           12\n",
       "['Sushi Bars', 'Japanese', 'Chinese', 'Restaurants']                              12\n",
       "['Creperies', 'Food Stands', 'Restaurants']                                       12\n",
       "['Mongolian', 'Restaurants']                                                      12\n",
       "['Mediterranean', 'Italian', 'Pizza', 'Restaurants']                              12\n",
       "['Salvadoran', 'Latin American', 'Restaurants']                                   12\n",
       "['Hot Dogs', 'Restaurants']                                                       12\n",
       "['Burgers', 'Breakfast & Brunch', 'Restaurants']                                  12\n",
       "['Southern', 'Restaurants']                                                       12\n",
       "['American (New)', 'Diners', 'Restaurants']                                       12\n",
       "['Gastropubs', 'American (New)', 'Restaurants']                                   12\n",
       "['Szechuan', 'Chinese', 'Restaurants']                                            12\n",
       "['American (Traditional)', 'Burgers', 'Sandwiches', 'Restaurants']                12\n",
       "['Afghan', 'Restaurants']                                                         11\n",
       "['Vegetarian', 'Ethiopian', 'Vegan', 'Restaurants']                               11\n",
       "['Restaurants', 'American (New)']                                                 11\n",
       "['Seafood', 'French', 'Restaurants']                                              11\n",
       "['Persian/Iranian', 'Restaurants']                                                11\n",
       "['Caribbean', 'Haitian', 'Restaurants']                                           11\n",
       "['Korean', 'Japanese', 'Sushi Bars', 'Restaurants']                               11\n",
       "['Mediterranean', 'Greek', 'Restaurants']                                         11\n",
       "['Chinese', 'Dim Sum', 'Restaurants']                                             11\n",
       "['American (Traditional)', 'Breakfast & Brunch', 'Cafes', 'Restaurants']          11\n",
       "['Burgers', 'Seafood', 'Fish & Chips', 'Restaurants']                             11\n",
       "['Malaysian', 'Restaurants']                                                      11\n",
       "['Trinidadian', 'Caribbean', 'Restaurants']                                       11\n",
       "['Burgers', 'Pizza', 'Restaurants']                                               11\n",
       "['Modern European', 'Restaurants']                                                11\n",
       "['Food Stands', 'Hot Dogs', 'Restaurants']                                        11\n",
       "['Indian', 'Mediterranean', 'Restaurants']                                        11\n",
       "['Modern European', 'Restaurants', 'Belgian']                                     11\n",
       "['Breakfast & Brunch', 'Delis', 'Restaurants']                                    11\n",
       "['Delis', 'Turkish', 'Restaurants']                                               11\n",
       "['Breakfast & Brunch', 'Cafes', 'Ethiopian', 'Restaurants']                       11\n",
       "['Live/Raw Food', 'Vegan', 'Restaurants']                                         11\n",
       "['Greek', 'American (New)', 'Restaurants']                                        10\n",
       "['Mediterranean', 'Moroccan', 'Restaurants']                                      10\n",
       "['Seafood', 'Japanese', 'Sushi Bars', 'Restaurants']                              10\n",
       "['Fast Food', 'Food Stands', 'Restaurants']                                       10\n",
       "['Restaurants', 'Sandwiches']                                                     10\n",
       "['Cajun/Creole', 'Diners', 'Restaurants']                                         10\n",
       "['Soup', 'Delis', 'Restaurants']                                                  10\n",
       "['Polish', 'Delis', 'Restaurants']                                                10\n",
       "['Vegetarian', 'Indian', 'Restaurants']                                           10\n",
       "['Seafood', 'Live/Raw Food', 'Restaurants']                                       10\n",
       "['Fast Food', 'Buffets', 'Chinese', 'Restaurants']                                10\n",
       "['Greek', 'Pizza', 'Mediterranean', 'Restaurants']                                10\n",
       "['Italian', 'Basque', 'Spanish', 'Restaurants']                                   10\n",
       "['Vietnamese', 'Food Court', 'Sandwiches', 'Restaurants']                         10\n",
       "['Vegetarian', 'Gluten-Free', 'Vegan', 'Restaurants']                              9\n",
       "['German', 'Fast Food', 'Restaurants']                                             9\n",
       "['Barbeque', 'Korean', 'Food Court', 'Restaurants']                                9\n",
       "['Cantonese', 'Barbeque', 'Chinese', 'Restaurants']                                9\n",
       "['Seafood', 'Diners', 'Restaurants']                                               9\n",
       "['Vietnamese', 'Japanese', 'Restaurants']                                          9\n",
       "['Seafood', 'Fish & Chips', 'Restaurants']                                         9\n",
       "['Gluten-Free', 'Japanese', 'Sushi Bars', 'Restaurants']                           9\n",
       "['Thai', 'Vegetarian', 'Restaurants']                                              9\n",
       "['Asian Fusion', 'Vegetarian', 'Delis', 'Restaurants']                             9\n",
       "['Delis', 'Mexican', 'Restaurants']                                                9\n",
       "['Burgers', 'Seafood', 'Restaurants']                                              9\n",
       "['Fast Food', 'Hot Dogs', 'Restaurants']                                           9\n",
       "['American (Traditional)', 'Chinese', 'Restaurants']                               9\n",
       "['Delis', 'Buffets', 'Restaurants']                                                8\n",
       "['Southern', 'Soul Food', 'Restaurants']                                           8\n",
       "['Buffets', 'Salad', 'Restaurants']                                                8\n",
       "['Vegetarian', 'Vietnamese', 'Delis', 'Restaurants']                               8\n",
       "['Dim Sum', 'Taiwanese', 'Chinese', 'Restaurants']                                 8\n",
       "['Seafood', 'Southern', 'Soul Food', 'Restaurants']                                8\n",
       "['Spanish', 'Restaurants']                                                         8\n",
       "['Asian Fusion', 'Tapas Bars', 'Thai', 'Restaurants']                              8\n",
       "['American (New)', 'Breakfast & Brunch', 'Restaurants']                            8\n",
       "['Asian Fusion', 'Korean', 'Sandwiches', 'Restaurants']                            8\n",
       "['American (New)', 'Tapas/Small Plates', 'Restaurants']                            8\n",
       "['Cantonese', 'Vietnamese', 'Chinese', 'Restaurants']                              8\n",
       "['Fast Food', 'Restaurants']                                                       8\n",
       "['Asian Fusion', 'Buffets', 'Restaurants']                                         8\n",
       "['Russian', 'Cafes', 'Restaurants']                                                8\n",
       "['Greek', 'Mediterranean', 'French', 'Restaurants']                                7\n",
       "['Caribbean', 'Restaurants']                                                       7\n",
       "['Barbeque', 'Vietnamese', 'Chinese', 'Restaurants']                               7\n",
       "['Breakfast & Brunch', 'Cafes', 'Vegan', 'Restaurants']                            7\n",
       "['Chinese', 'Sushi Bars', 'Restaurants']                                           7\n",
       "['Vegan', 'Restaurants']                                                           7\n",
       "['Buffets', 'Restaurants']                                                         7\n",
       "['Burgers', 'Cheesesteaks', 'Barbeque', 'Restaurants']                             7\n",
       "['Turkish', 'Sandwiches', 'Middle Eastern', 'Restaurants']                         7\n",
       "['Soup', 'Sandwiches', 'Restaurants']                                              7\n",
       "['Indian', 'Tapas/Small Plates', 'American (New)', 'Restaurants']                  7\n",
       "['Indonesian', 'Taiwanese', 'Chinese', 'Restaurants']                              7\n",
       "['Cafes', 'Gluten-Free', 'Restaurants']                                            7\n",
       "['Vegetarian', 'Ethiopian', 'Restaurants']                                         7\n",
       "['Pizza', 'Italian', 'Fast Food', 'Restaurants']                                   7\n",
       "['Korean', 'Barbeque', 'Chicken Wings', 'Restaurants']                             7\n",
       "['Asian Fusion', 'Korean', 'Hawaiian', 'Restaurants']                              7\n",
       "['Thai', 'Laotian', 'Restaurants']                                                 7\n",
       "['Thai', 'Japanese', 'Sushi Bars', 'Restaurants']                                  7\n",
       "['Tapas/Small Plates', 'Restaurants']                                              7\n",
       "['Scandinavian', 'Restaurants']                                                    7\n",
       "['Asian Fusion', 'Indonesian', 'Restaurants']                                      7\n",
       "['American (Traditional)', 'Soup', 'Restaurants']                                  6\n",
       "['Vegetarian', 'Thai', 'Vegan', 'Restaurants']                                     6\n",
       "['Burgers', 'Fish & Chips', 'Restaurants']                                         6\n",
       "['Breakfast & Brunch', 'Greek', 'Restaurants']                                     6\n",
       "['Vietnamese', 'French', 'Restaurants']                                            6\n",
       "['Gluten-Free', 'Vegan', 'Restaurants']                                            6\n",
       "['Food Stands', 'Mexican', 'Restaurants']                                          6\n",
       "['Asian Fusion', 'Chicken Wings', 'Chinese', 'Restaurants']                        6\n",
       "['Pizza', 'Vegan', 'Restaurants']                                                  6\n",
       "['Barbeque', 'American (New)', 'Restaurants']                                      6\n",
       "['Asian Fusion', 'Vietnamese', 'Restaurants']                                      6\n",
       "['Breakfast & Brunch', 'Burgers', 'American (New)', 'Restaurants']                 6\n",
       "['Tapas Bars', 'Italian', 'Restaurants']                                           6\n",
       "['Korean', 'Fast Food', 'Japanese', 'Restaurants']                                 6\n",
       "['Cafes', 'Mediterranean', 'Restaurants']                                          6\n",
       "['Pizza', 'Mediterranean', 'Restaurants']                                          6\n",
       "['American (Traditional)', 'Soup', 'Sandwiches', 'Restaurants']                    6\n",
       "['Fast Food', 'American (Traditional)', 'Restaurants']                             6\n",
       "['Halal', 'Restaurants']                                                           6\n",
       "['Seafood', 'American (New)', 'Live/Raw Food', 'Restaurants']                      5\n",
       "['Breakfast & Brunch', 'Italian', 'Pizza', 'Restaurants']                          5\n",
       "['Turkish', 'Italian', 'Mediterranean', 'Restaurants']                             5\n",
       "['Lebanese', 'Mediterranean', 'Middle Eastern', 'Restaurants']                     5\n",
       "['Barbeque', 'Mediterranean', 'Restaurants']                                       5\n",
       "['Vegetarian', 'Pizza', 'Vegan', 'Restaurants']                                    5\n",
       "['Breakfast & Brunch', 'Sandwiches', 'Filipino', 'Restaurants']                    5\n",
       "['Kosher', 'Burgers', 'Halal', 'Restaurants']                                      5\n",
       "['Seafood', 'Indian', 'Restaurants']                                               5\n",
       "['Vegan', 'Live/Raw Food', 'Restaurants']                                          5\n",
       "['Mexican', 'Caribbean', 'Restaurants']                                            5\n",
       "['Chicken Wings', 'Restaurants']                                                   5\n",
       "['Fast Food', 'Chicken Wings', 'Restaurants']                                      5\n",
       "['Tapas/Small Plates', 'Breakfast & Brunch', 'Restaurants']                        5\n",
       "['Asian Fusion', 'American (New)', 'Restaurants']                                  5\n",
       "['Vegetarian', 'Live/Raw Food', 'Restaurants']                                     5\n",
       "['Tapas Bars', 'Restaurants', 'Pizza']                                             5\n",
       "['Italian', 'American (New)', 'Restaurants']                                       5\n",
       "['Food Stands', 'Mexican', 'Salvadoran', 'Latin American', 'Restaurants']          4\n",
       "['Belgian', 'Sandwiches', 'Restaurants']                                           4\n",
       "['Delis', 'Japanese', 'Restaurants']                                               4\n",
       "['Breakfast & Brunch', 'American (New)', 'Diners', 'Restaurants']                  4\n",
       "['Breakfast & Brunch', 'Belgian', 'Restaurants']                                   4\n",
       "['Buffets', 'Chinese', 'Restaurants']                                              4\n",
       "['Cafes', 'Delis', 'Restaurants']                                                  4\n",
       "['Asian Fusion', 'Burgers', 'Restaurants']                                         4\n",
       "['American (Traditional)', 'Mediterranean', 'Restaurants']                         4\n",
       "['German', 'Cafes', 'Sandwiches', 'Restaurants']                                   4\n",
       "['Puerto Rican', 'Caribbean', 'Restaurants']                                       4\n",
       "['Italian', 'Cafes', 'Sandwiches', 'Restaurants']                                  4\n",
       "['Burgers', 'Chicken Wings', 'Restaurants']                                        4\n",
       "['Vegetarian', 'Pizza', 'Restaurants']                                             4\n",
       "['Delis', 'Indian', 'Restaurants']                                                 4\n",
       "['Vietnamese', 'Sandwiches', 'Chinese', 'Restaurants']                             4\n",
       "['Vietnamese', 'Cafes', 'Restaurants']                                             3\n",
       "['Italian', 'Sandwiches', 'Restaurants']                                           3\n",
       "['Seafood', 'Cajun/Creole', 'Diners', 'Restaurants']                               3\n",
       "['Delis', 'Comfort Food', 'Sandwiches', 'Restaurants']                             3\n",
       "['Cafes', 'Sandwiches', 'Japanese', 'Restaurants']                                 3\n",
       "['Italian', 'Food Stands', 'Restaurants']                                          3\n",
       "['Caribbean', 'Latin American', 'Restaurants']                                     3\n",
       "['Himalayan/Nepalese', 'Restaurants']                                              3\n",
       "['Asian Fusion', 'Thai', 'Restaurants']                                            3\n",
       "['Burgers', 'Barbeque', 'Restaurants']                                             3\n",
       "['African', 'Ethiopian', 'Restaurants']                                            3\n",
       "['Kosher', 'Vegetarian', 'Vegan', 'Chinese', 'Restaurants']                        3\n",
       "['Seafood', 'Cajun/Creole', 'Soul Food', 'Restaurants']                            3\n",
       "['Cafes', 'Latin American', 'Restaurants']                                         3\n",
       "['Creperies', 'Sandwiches', 'Cafes', 'Restaurants']                                3\n",
       "['Cuban', 'Venezuelan', 'Colombian', 'Latin American', 'Restaurants']              3\n",
       "['American (Traditional)', 'Modern European', 'Restaurants']                       3\n",
       "['Barbeque', 'Sandwiches', 'Restaurants']                                          2\n",
       "['Seafood', 'Thai', 'Restaurants']                                                 2\n",
       "['Caribbean', 'Cuban', 'Restaurants']                                              2\n",
       "['Creperies', 'Sandwiches', 'French', 'Restaurants']                               2\n",
       "['Scottish', 'Restaurants']                                                        2\n",
       "['Burgers', 'Pizza', 'American (New)', 'Restaurants']                              2\n",
       "['Lebanese', 'Middle Eastern', 'Restaurants']                                      2\n",
       "['Fish & Chips', 'Restaurants']                                                    2\n",
       "['Asian Fusion', 'Hot Pot', 'Japanese', 'Restaurants']                             2\n",
       "['Burgers', 'Japanese', 'Restaurants']                                             2\n",
       "['Indonesian', 'Restaurants']                                                      2\n",
       "['Cafes', 'Chinese', 'Restaurants']                                                2\n",
       "['American (New)', 'Cafes', 'Restaurants']                                         2\n",
       "['Australian', 'Restaurants']                                                      2\n",
       "['Pizza', 'Sandwiches', 'Hot Dogs', 'Restaurants']                                 2\n",
       "['Cafes', 'American (New)', 'Restaurants']                                         2\n",
       "['Kosher', 'Restaurants']                                                          2\n",
       "['Creperies', 'Food Court', 'Restaurants']                                         2\n",
       "['German', 'Gastropubs', 'Hot Dogs', 'Restaurants']                                2\n",
       "['Breakfast & Brunch', 'Cafes', 'Sandwiches', 'Restaurants']                       2\n",
       "['Vietnamese', 'Tapas Bars', 'Restaurants']                                        2\n",
       "['Senegalese', 'African', 'Restaurants']                                           2\n",
       "['American (Traditional)', 'Vegetarian', 'Vegan', 'Restaurants']                   1\n",
       "['Asian Fusion', 'Korean', 'Restaurants']                                          1\n",
       "['Korean', 'Cafes', 'Restaurants']                                                 1\n",
       "['Steakhouses', 'Brazilian', 'Restaurants']                                        1\n",
       "['Chinese', 'Dim Sum', 'Restaurants', 'Barbeque']                                  1\n",
       "['American (New)', 'Salvadoran', 'Latin American', 'Restaurants']                  1\n",
       "['Asian Fusion', 'Korean', 'Mexican', 'Restaurants']                               1\n",
       "['Spanish', 'Mediterranean', 'Moroccan', 'Restaurants']                            1\n",
       "['African', 'Mediterranean', 'Restaurants']                                        1\n",
       "['Persian/Iranian', 'Sandwiches', 'Middle Eastern', 'Restaurants']                 1\n",
       "['Thai', 'Pakistani', 'Restaurants']                                               1\n",
       "['Mongolian', 'Chinese', 'Restaurants']                                            1\n",
       "['Italian', 'Cafes', 'Restaurants']                                                1\n",
       "['Steakhouses', 'American (New)', 'Restaurants']                                   1\n",
       "['Cheesesteaks', 'Food Stands', 'Hot Dogs', 'Restaurants']                         1\n",
       "['American (Traditional)', 'Seafood', 'Fish & Chips', 'Restaurants']               1\n",
       "['American (Traditional)', 'Delis', 'Restaurants']                                 1\n",
       "['Mongolian', 'Japanese', 'Restaurants']                                           1\n",
       "['Comfort Food', 'Restaurants']                                                    1\n",
       "['Breakfast & Brunch', 'Seafood', 'Restaurants']                                   1\n",
       "['Egyptian', 'Mediterranean', 'Middle Eastern', 'Restaurants']                     1\n",
       "['Cafes', 'Southern', 'Restaurants']                                               1\n",
       "['Seafood', 'Cajun/Creole', 'Restaurants']                                         1\n",
       "['Greek', 'Italian', 'Pizza', 'Restaurants']                                       1\n",
       "['Salad', 'Restaurants']                                                           1\n",
       "['Sandwiches', 'Delis', 'Restaurants']                                             1\n",
       "Name: cuisines_offered, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df['cuisines_offered'].value_counts()))\n",
    "df['cuisines_offered'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(df['avg_rating'].value_counts()))\n",
    "print(len(df['zipcode'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63551402 0.7027027  0.65486726 0.63636364 0.51685393]\n",
      "Average F1-Score: 0.62926\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('preprocess', ColumnTransformer(\n",
    "        [('cuisines_offered', CountVectorizer(), 'cuisines_offered'),\n",
    "         ('zipcode', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['zipcode']),\n",
    "         ('num_reviews', CountVectorizer(token_pattern='\\d+'), 'num_reviews'),\n",
    "         ('avg_rating', CountVectorizer(token_pattern='\\d+'), 'avg_rating'),\n",
    "         ('text', TfidfVectorizer(\n",
    "                    stop_words='english',\n",
    "                    strip_accents='unicode',\n",
    "                    min_df=3,\n",
    "                    max_df=0.5,\n",
    "                    ngram_range=(1, 3),\n",
    "                    max_features=500), 'preprocessed_texts')],\n",
    "        remainder='passthrough',\n",
    "    )),\n",
    "    ('clf', MultinomialNB())\n",
    "], verbose=False)\n",
    "\n",
    "# pipeline.fit(X_train, y_train)\n",
    "# y_pred = pipeline.predict(X_test)\n",
    "# scores = metrics.f1_score(y_test, y_pred)\n",
    "scores = cross_val_score(pipeline, train_preprocessed, train_labels, cv=5, scoring= 'f1')\n",
    "print(scores)\n",
    "print(\"Average F1-Score: %0.5f\" % np.average(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63551402 0.69090909 0.65486726 0.64220183 0.50574713]\n",
      "Average F1-Score: 0.62585\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('union', ColumnTransformer(\n",
    "        [('cuisines_offered', CountVectorizer(), 'cuisines_offered'),\n",
    "         ('zipcode', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['zipcode']),\n",
    "         ('num_reviews', CountVectorizer(token_pattern='\\d+'), 'num_reviews'),\n",
    "         ('avg_rating', CountVectorizer(token_pattern='\\d+'), 'avg_rating'),\n",
    "         ('text', TfidfVectorizer(\n",
    "                stop_words='english',\n",
    "                strip_accents='unicode',\n",
    "                min_df=15,\n",
    "                max_df=0.5,\n",
    "                ngram_range=(1, 3),\n",
    "                max_features=500), 'text')],\n",
    "        remainder='passthrough',\n",
    "    )),\n",
    "    ('clf', MultinomialNB())\n",
    "], verbose=False)\n",
    "\n",
    "# pipeline.fit(X_train, y_train)\n",
    "# y_pred = pipeline.predict(X_test)\n",
    "# score = metrics.f1_score(y_test, y_pred)\n",
    "scores = cross_val_score(pipeline, train, train_labels, cv=5, scoring= 'f1')\n",
    "print(scores)\n",
    "print(\"Average F1-Score: %0.5f\" % np.average(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(clf, X, y, vectorizer, text_col='text'):\n",
    "    pipeline = Pipeline([\n",
    "        ('union', ColumnTransformer(\n",
    "        [('cuisines_offered', CountVectorizer(min_df=10), 'cuisines_offered'),\n",
    "         ('zipcode', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['zipcode']),\n",
    "         ('num_reviews', CountVectorizer(max_df=7, token_pattern='\\d+'), 'num_reviews'),\n",
    "         ('avg_rating', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['avg_rating']),\n",
    "         ('text', vectorizer, text_col)],\n",
    "        remainder='passthrough',\n",
    "    )),\n",
    "        ('clf', clf)\n",
    "    ], verbose=False)\n",
    "    scores = cross_val_score(pipeline, X, y, cv=5, scoring= 'f1_macro')\n",
    "    print(clf)\n",
    "    print(scores)\n",
    "    cv_score = np.average(scores)\n",
    "    return cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(random_state=SEED, n_estimators=500, n_jobs=-1),\n",
    "    'Support Vector Machine': svm.SVC(),\n",
    "    'XGBoost': XGBClassifier(n_estimators=500, \n",
    "                            max_depth=5, \n",
    "                            learning_rate=0.2, \n",
    "                            objective='binary:logistic',\n",
    "                            scale_pos_weight=2,\n",
    "                            n_jobs=-1,\n",
    "                            random_state=SEED),\n",
    "    'Gradient Boosting': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "                    stop_words='english',\n",
    "                    strip_accents='unicode',\n",
    "                    min_df=3,\n",
    "                    max_df=0.5,\n",
    "                    ngram_range=(1, 3),\n",
    "                    max_features=500)\n",
    "bow = CountVectorizer(\n",
    "                stop_words=STOP_WORDS,\n",
    "                strip_accents='unicode',\n",
    "                min_df=5,\n",
    "                max_df=0.6,\n",
    "                ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB()\n",
      "[0.60828157 0.66969697 0.68804714 0.61464646 0.61308316]\n",
      "Naive Bayes: 0.638751062037948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\besth\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\besth\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\besth\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\besth\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\besth\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "[0.63636364 0.52192982 0.5962963  0.64220183 0.65485665]\n",
      "Logistic Regression: 0.6103296491826835\n",
      "RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=30)\n",
      "[0.66338599 0.61438679 0.58659924 0.64026403 0.668357  ]\n",
      "Random Forest: 0.6345986095745193\n",
      "SVC()\n",
      "[0.63061152 0.61330795 0.5968172  0.60260417 0.54821774]\n",
      "Support Vector Machine: 0.5983117172144025\n",
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
      "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=0.2, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=500, n_jobs=-1, num_parallel_tree=None,\n",
      "              random_state=30, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=2, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None)\n",
      "[0.615      0.63299663 0.54055914 0.60430561 0.63274933]\n",
      "XGBoost: 0.6051221426220662\n",
      "GradientBoostingClassifier()\n",
      "[0.6247608  0.57766173 0.59602426 0.67879094 0.62152778]\n",
      "Gradient Boosting: 0.6197530994971452\n"
     ]
    }
   ],
   "source": [
    "for clf_name, clf in classifiers.items():\n",
    "    cv_score = test_classifier(clf, train, train_labels, \n",
    "                               vectorizer=bow, text_col='text')\n",
    "    print('{}: {}'.format(clf_name, cv_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB()\n",
      "[0.59880637 0.72474747 0.68783693 0.62385321 0.60336803]\n",
      "Naive Bayes: 0.6477224016277434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\besth\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\besth\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\besth\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\besth\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\besth\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "[0.54530423 0.58023107 0.62372653 0.6513468  0.6761735 ]\n",
      "Logistic Regression: 0.6153564259182163\n",
      "RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=30)\n",
      "[0.63443004 0.59547908 0.58590122 0.61308316 0.63050847]\n",
      "Random Forest: 0.6118803977093185\n",
      "SVC()\n",
      "[0.56785714 0.61074819 0.5968172  0.59444493 0.51601323]\n",
      "Support Vector Machine: 0.5771761382483058\n",
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
      "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=0.2, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=500, n_jobs=-1, num_parallel_tree=None,\n",
      "              random_state=30, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=2, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None)\n",
      "[0.56305859 0.59547908 0.53242965 0.53242965 0.55959596]\n",
      "XGBoost: 0.5565985863438833\n",
      "GradientBoostingClassifier()\n",
      "[0.60828157 0.6138664  0.58701692 0.64220183 0.6120339 ]\n",
      "Gradient Boosting: 0.612680125378618\n"
     ]
    }
   ],
   "source": [
    "for clf_name, clf in classifiers.items():\n",
    "    cv_score = test_classifier(clf, train_preprocessed, train_labels, \n",
    "                               vectorizer=bow, text_col='preprocessed_texts')\n",
    "    print('{}: {}'.format(clf_name, cv_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB()\n",
      "[0.65351459 0.72474747 0.668357   0.66947439 0.60507246]\n",
      "Naive Bayes: 0.6642331837755213\n",
      "LogisticRegression()\n",
      "[0.63588216 0.69714574 0.66902834 0.62372653 0.63916476]\n",
      "Logistic Regression: 0.6529895058523685\n",
      "RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=30)\n",
      "[0.64542524 0.68741565 0.63225371 0.6513468  0.6292517 ]\n",
      "Random Forest: 0.6491386219009174\n",
      "SVC()\n",
      "[0.63527851 0.72474747 0.66902834 0.62271    0.62594372]\n",
      "Support Vector Machine: 0.6555416107222085\n",
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
      "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=0.2, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=500, n_jobs=-1, num_parallel_tree=None,\n",
      "              random_state=30, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=2, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None)\n",
      "[0.60645644 0.54031714 0.61464646 0.6138664  0.56822587]\n",
      "XGBoost: 0.5887024637586473\n",
      "GradientBoostingClassifier()\n",
      "[0.59087528 0.63274933 0.66009271 0.6513468  0.63225371]\n",
      "Gradient Boosting: 0.6334635654584677\n"
     ]
    }
   ],
   "source": [
    "for clf_name, clf in classifiers.items():\n",
    "    cv_score = test_classifier(clf, train, train_labels, \n",
    "                               vectorizer=tfidf, text_col='text')\n",
    "    print('{}: {}'.format(clf_name, cv_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB()\n",
      "[0.62650104 0.72474747 0.668357   0.68783693 0.60507246]\n",
      "Naive Bayes: 0.6625029797815201\n",
      "LogisticRegression()\n",
      "[0.64519064 0.72456199 0.69683944 0.59547908 0.61754386]\n",
      "Logistic Regression: 0.6559230035971904\n",
      "RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=30)\n",
      "[0.6090586  0.63274933 0.6138664  0.64993239 0.63150778]\n",
      "Random Forest: 0.6274228970125558\n",
      "SVC()\n",
      "[0.61704244 0.72474747 0.65951878 0.59547908 0.62594372]\n",
      "Support Vector Machine: 0.6445463003313365\n",
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
      "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=0.2, max_delta_step=None, max_depth=5,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=500, n_jobs=-1, num_parallel_tree=None,\n",
      "              random_state=30, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=2, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None)\n",
      "[0.59060458 0.51966102 0.54055914 0.5025355  0.54031714]\n",
      "XGBoost: 0.5387354749226577\n",
      "GradientBoostingClassifier()\n",
      "[0.65454545 0.61308316 0.65064103 0.66055046 0.63781205]\n",
      "Gradient Boosting: 0.6433264301147679\n"
     ]
    }
   ],
   "source": [
    "for clf_name, clf in classifiers.items():\n",
    "    cv_score = test_classifier(clf, train_preprocessed, train_labels, \n",
    "                               vectorizer=tfidf, text_col='preprocessed_texts')\n",
    "    print('{}: {}'.format(clf_name, cv_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(y_pred, filepath):\n",
    "    with open(filepath, 'w') as f:\n",
    "        f.write('yinanhu3\\n')\n",
    "        for label in y_pred:\n",
    "            f.write(str(int(label)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('preprocess', ColumnTransformer(\n",
    "        [('cuisines_offered', CountVectorizer(min_df=10), 'cuisines_offered'),\n",
    "         ('zipcode', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['zipcode']),\n",
    "         ('num_reviews', CountVectorizer(max_df=7, token_pattern='\\d+'), 'num_reviews'),\n",
    "         ('avg_rating', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['avg_rating']),\n",
    "         ('text', TfidfVectorizer(\n",
    "                    stop_words='english',\n",
    "                    strip_accents='unicode',\n",
    "                    min_df=2,\n",
    "                    max_df=0.4,\n",
    "                    ngram_range=(1, 3),\n",
    "                    max_features=2000), 'preprocessed_texts')],\n",
    "        remainder='passthrough',\n",
    "    )),\n",
    "    ('clf', MultinomialNB())\n",
    "], verbose=False)\n",
    "\n",
    "pipeline.fit(train_preprocessed, train_labels)\n",
    "y_pred = pipeline.predict(test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_path ='submission7_yinanhu3.txt'\n",
    "create_submission(y_pred, submit_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'submission7_yinanhu3.txt'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "submit_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission completed successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!python submit.py yinanhu3 {submit_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
